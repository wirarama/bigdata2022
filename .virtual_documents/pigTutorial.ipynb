!sudo rm -rf /tmp/hadoop*


!hadoop dfsadmin -safemode leave


!export PIG_HOME=/Users/wiraramawedashwara/hadoop/pig
!export PATH=$PATH:$PIG_HOME/bin





!export JAVA_HOME=/home/wirarama/jdk8
!export PATH=$PATH:$JAVA_HOME/bin


!~/hadoop/hadoop/bin/hdfs namenode -format


!~/hadoop/hadoop/sbin/start-dfs.sh


!~/hadoop/hadoop/bin/hdfs dfs -mkdir /pigdata


!~/hadoop/hadoop/bin/hdfs dfs -put avocado.csv /pigdata/


 hdfs dfs -put C:\Users\wirar\OneDrive\Documents\GitHub\bigdata\avocado.csv /pigdata/


!~/hadoop/hadoop/bin/hdfs dfs -ls /pigdata/


!~/hadoop/hadoop/bin/hdfs dfs -cat /pigoutputfilter/part-m-00000








test = LOAD 'hdfs://localhost:9000/pigdata/avocado.csv' USING PigStorage(',') as (index:int,tgl:chararray, a:float, b:float, c:float, d:float, e:float, f:float, g:float, h:float );





STORE test INTO ' hdfs://localhost:9000/pigoutput/ ' USING PigStorage (',');


filterData = FILTER test BY b > 50000 AND a > 0.5;
DUMP filterData;


STORE filterData INTO ' hdfs://localhost:9000/pigoutputfilter/ ' USING PigStorage (',');


!~/hadoop/hadoop/bin/hdfs dfs -cat /pigoutputfilter/


SELECT a,b,c,d FROM test


foreachData = FOREACH test GENERATE tgl,a+h-e,b/a+g,(b+c)/d;
DUMP foreachData;


STORE foreachData INTO ' hdfs://localhost:9000/pigoutputforeach/ ' USING PigStorage (',');


!~/hadoop/bin/hdfs dfs -rm -rf /pigoutputforeach/


!~/hadoop/bin/hdfs dfs -cat /pigoutput/*


!~/hadoop/hadoop/sbin/stop-dfs.sh
