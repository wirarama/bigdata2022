{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]\r\n",
      "  CLASSNAME            run the class named CLASSNAME\r\n",
      " or\r\n",
      "  where COMMAND is one of:\r\n",
      "  fs                   run a generic filesystem user client\r\n",
      "  version              print the version\r\n",
      "  jar <jar>            run a jar file\r\n",
      "                       note: please use \"yarn jar\" to launch\r\n",
      "                             YARN applications, not this command.\r\n",
      "  checknative [-a|-h]  check native hadoop and compression libraries availability\r\n",
      "  distcp <srcurl> <desturl> copy file or directories recursively\r\n",
      "  archive -archiveName NAME -p <parent path> <src>* <dest> create a hadoop archive\r\n",
      "  classpath            prints the class path needed to get the\r\n",
      "  credential           interact with credential providers\r\n",
      "                       Hadoop jar and the required libraries\r\n",
      "  daemonlog            get/set the log level for each daemon\r\n",
      "  trace                view and modify Hadoop tracing settings\r\n",
      "\r\n",
      "Most commands print help when invoked w/o parameters.\r\n"
     ]
    }
   ],
   "source": [
    "!~/hadoop/hadoop/bin/hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xed ~/hadoop/hadoop/etc/hadoop/core-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "    <property>\n",
    "        <name>fs.defaultFS</name>\n",
    "        <value>hdfs://localhost:9000</value>\n",
    "    </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xed ~/hadoop/hadoop/etc/hadoop/hdfs-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "    <property>\n",
    "        <name>dfs.replication</name>\n",
    "        <value>1</value>\n",
    "    </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/bin/hdfs namenode -format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/sbin/start-dfs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:50070/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/sbin/stop-dfs.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
