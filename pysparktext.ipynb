{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5da6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e8229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "filetext = open('text.csv','w')\n",
    "makanan = ['sate','bakso','mie ayam','gado gado','ayam geprek','tahu tek']\n",
    "tujuan = ['lapangan sepak bola','mall','pantai','gunung','hutan','isekai']\n",
    "for x in range(10000):\n",
    "    if randint(0,1)==0:\n",
    "        filetext.write('\"saya suka makan '+\n",
    "                       str(makanan[randint(0,len(makanan)-1)])+\n",
    "                      '\",0\\n')\n",
    "    else:\n",
    "        filetext.write('\"saya sering pergi ke '+\n",
    "                       str(tujuan[randint(0,len(tujuan)-1)])+\n",
    "                      '\",1\\n')\n",
    "filetext.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3b2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "schema = StructType([\n",
    "    StructField(\"text\", StringType()),\n",
    "    StructField(\"label\", IntegerType())\n",
    "])\n",
    "txt = spark.read.csv('text.csv', header=False, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba254be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----+---------------------------------+\n",
      "|text                       |label|words                            |\n",
      "+---------------------------+-----+---------------------------------+\n",
      "|saya sering pergi ke isekai|1    |[saya, sering, pergi, ke, isekai]|\n",
      "|saya suka makan bakso      |0    |[saya, suka, makan, bakso]       |\n",
      "|saya sering pergi ke isekai|1    |[saya, sering, pergi, ke, isekai]|\n",
      "|saya suka makan mie ayam   |0    |[saya, suka, makan, mie, ayam]   |\n",
      "+---------------------------+-----+---------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "wrangled = txt.withColumn('text', regexp_replace(txt.text, '[_():;,.!?\\\\-]', ' '))\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '[0-9]', ' '))\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))\n",
    "wrangled = Tokenizer(inputCol='text', outputCol='words').transform(wrangled)\n",
    "wrangled.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c525815e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------+\n",
      "|terms                            |features                                                                                                      |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------+\n",
      "|[saya, sering, pergi, ke, isekai]|(1024,[145,298,411,487,965],[0.6862715618238534,2.4687396723244617,0.6862715618238534,0.0,0.6862715618238534])|\n",
      "|[saya, suka, makan, bakso]       |(1024,[47,398,487,498],[0.6998690518691655,0.6998690518691655,0.0,2.498699971920336])                         |\n",
      "|[saya, sering, pergi, ke, isekai]|(1024,[145,298,411,487,965],[0.6862715618238534,2.4687396723244617,0.6862715618238534,0.0,0.6862715618238534])|\n",
      "|[saya, suka, makan, mie, ayam]   |(1024,[47,334,398,487,688],[0.6998690518691655,1.7898614615657151,0.6998690518691655,0.0,2.501136026718217])  |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover, HashingTF, IDF\n",
    "txt = wrangled.select('words', 'label')\n",
    "wrangled = StopWordsRemover(inputCol='words', outputCol='terms').transform(txt)\n",
    "wrangled = HashingTF(inputCol='terms', outputCol='hash', numFeatures=1024).transform(wrangled)\n",
    "tf_idf = IDF(inputCol='hash', outputCol='features').fit(wrangled).transform(wrangled)\n",
    "tf_idf.select('terms', 'features').show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "384521d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       0.0|  965|\n",
      "|    1|       1.0|  974|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "txt = tf_idf.select('label', 'features')\n",
    "txt_train, txt_test = txt.randomSplit([0.8, 0.2], seed=13)\n",
    "logistic = LogisticRegression(regParam=0.2).fit(txt_train)\n",
    "prediction = logistic.transform(txt_test)\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c6421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
