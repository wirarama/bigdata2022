{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -rf /tmp/hadoop*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop dfsadmin -safemode leave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PIG_HOME=/Users/wiraramawedashwara/hadoop/pig\n",
    "!export PATH=$PATH:$PIG_HOME/bin"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "export HADOOP_HOME=/Users/wiraramawedashwara/hadoop/hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export JAVA_HOME=/home/wirarama/jdk8\n",
    "!export PATH=$PATH:$JAVA_HOME/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/bin/hdfs namenode -format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/sbin/start-dfs.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/bin/hdfs dfs -mkdir /pigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/bin/hdfs dfs -put avocado.csv /pigdata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " hdfs dfs -put C:\\Users\\wirar\\OneDrive\\Documents\\GitHub\\bigdata\\avocado.csv /pigdata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/bin/hdfs dfs -ls /pigdata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/bin/hdfs dfs -cat /pigoutputfilter/part-m-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open the file pig.cmd in any editor like notpad / notepad++\n",
    "look for the line set HADOOP_BIN_PATH=%HADOOP_HOME%\\bin\n",
    "replace this with set HADOOP_BIN_PATH=%HADOOP_HOME%\\libexec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pig -x mapreduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = LOAD 'hdfs://localhost:9000/pigdata/avocado.csv' USING PigStorage(',') as (index:int,tgl:chararray, a:float, b:float, c:float, d:float, e:float, f:float, g:float, h:float );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test = LOAD 'hdfs://localhost:9000/pigdata/avacado.csv' USING PigStorage(',') as (index:int,tgl:chararray, a:float, b:float, c:float, d:float, e:float, f:float, g:float, h:float );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE test INTO ' hdfs://localhost:9000/pigoutput/ ' USING PigStorage (',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterData = FILTER test BY b > 50000 AND a > 0.5;\n",
    "DUMP filterData;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE filterData INTO ' hdfs://localhost:9000/pigoutputfilter/ ' USING PigStorage (',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/hadoop/hadoop/bin/hdfs dfs -cat /pigoutputfilter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT a,b,c,d FROM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreachData = FOREACH test GENERATE tgl,a+h-e,b/a+g,(b+c)/d;\n",
    "DUMP foreachData;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE foreachData INTO ' hdfs://localhost:9000/pigoutputforeach/ ' USING PigStorage (',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: /Users/wiraramawedashwara/hadoop/bin/hdfs\n"
     ]
    }
   ],
   "source": [
    "!~/hadoop/bin/hdfs dfs -rm -rf /pigoutputforeach/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: /pigoutput/*\n"
     ]
    }
   ],
   "source": [
    "!~/hadoop/bin/hdfs dfs -cat /pigoutput/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/Users/wiraramawedashwara/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-2.10.2.jar) to method sun.security.krb5.Config.getInstance()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/10/26 09:13:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Stopping namenodes on [localhost]\n",
      "localhost: no namenode to stop\n",
      "localhost: stopping datanode\n",
      "Stopping secondary namenodes [0.0.0.0]\n",
      "0.0.0.0: no secondarynamenode to stop\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/Users/wiraramawedashwara/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-2.10.2.jar) to method sun.security.krb5.Config.getInstance()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/10/26 09:13:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "!~/hadoop/hadoop/sbin/stop-dfs.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
